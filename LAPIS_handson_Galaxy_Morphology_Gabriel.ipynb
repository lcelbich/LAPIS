{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<font size=\"5\"> Galaxy Morphology Classification in S-PLUS Images with Deep Learning\n",
        "    \n",
        "<font size=\"2\">\n",
        "    \n",
        "This notebook was developed for the XI La Plata International School (LAPIS) on Astronomy and Geophysics.\n",
        "The approach is based on <a href=\"https://academic.oup.com/mnras/article/507/2/1937/6328504\">De Bom et. al. 2021</a>\n",
        "<!-- <a href=\"www.clearnightsrthebest.com\">clearnightsrthebest.com</a> -->\n",
        "\n",
        "Notebook Author: Gabriel Teixeira (CBPF - Brazil)\n",
        "\n",
        "**Contact:** gteixeira@cbpf.br</font>\n",
        "\n",
        "<font size=\"2\">\n",
        "\n",
        "Please do not remove this disclaimer.</font>"
      ],
      "metadata": {
        "id": "23BFFCfa_alz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup & Imports\n"
      ],
      "metadata": {
        "id": "jLeqjHrgCgeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
        "import gc\n",
        "from google.colab import drive\n",
        "\n"
      ],
      "metadata": {
        "id": "hz6GRVzJCj9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load Preprocessed Dataset\n"
      ],
      "metadata": {
        "id": "psBgCnJLC1IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to your google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data = np.load('drive/MyDrive/dataset_morph.npz')# load the dataset\n",
        "x_data = data['x']\n",
        "y_data = data['y']\n"
      ],
      "metadata": {
        "id": "vTfZabRpCx4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 3. Utilities\n"
      ],
      "metadata": {
        "id": "gGA7Nf0pDPxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 - Elliptical\n",
        "# 1 - Spiral"
      ],
      "metadata": {
        "id": "tM2nmyrpEUEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cropping the image around the center\n",
        "def center_crop(image, target_height=128, target_width=128):\n",
        "    h, w = image.shape[:2]\n",
        "    start_y = (h - target_height) // 2\n",
        "    start_x = (w - target_width) // 2\n",
        "    return image[start_y:start_y + target_height, start_x:start_x + target_width]\n",
        "\n",
        "img = x_data[0]\n",
        "img_crop = center_crop(img)# np.array([center_crop(img) for img in x_data]) in case of multiple images at the same time\n",
        "print(f\"Original shape: {img.shape}\")\n",
        "print(f\"Cropped shape:  {img_crop.shape}\")\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "plt.imshow(img_crop)"
      ],
      "metadata": {
        "id": "lNQ3kt4z3WWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rotations and Flips\n",
        "\n",
        "# Rotate 180 degrees\n",
        "def rotate_180(image):\n",
        "    return np.rot90(image, k=2)\n",
        "\n",
        "# Flip vertically (up-down)\n",
        "def flip_vertical(image):\n",
        "    return np.flipud(image)\n",
        "\n",
        "# Flip horizontally (left-right)\n",
        "def flip_horizontal(image):\n",
        "    return np.fliplr(image)\n",
        "\n",
        "# Let's assume 'img' is a NumPy array (H, W, C)\n",
        "img = x_data[np.random.randint(len(x_data))]  # example image\n",
        "\n",
        "rotated = rotate_180(img)\n",
        "vflip = flip_vertical(img)\n",
        "hflip = flip_horizontal(img)\n",
        "\n",
        "# Plotting\n",
        "fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
        "axs[0].imshow(img)\n",
        "axs[0].set_title(\"Original\")\n",
        "axs[1].imshow(rotated)\n",
        "axs[1].set_title(\"Rotated 180Â°\")\n",
        "axs[2].imshow(vflip)\n",
        "axs[2].set_title(\"Vertical Flip\")\n",
        "axs[3].imshow(hflip)\n",
        "axs[3].set_title(\"Horizontal Flip\")\n",
        "\n",
        "for ax in axs:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "s1XQcX1nqgod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the training, test and validation datasets for DL"
      ],
      "metadata": {
        "id": "znk3I7JVIXjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_percentual = 0.2\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_data, y_data,           # your full dataset\n",
        "    test_size=test_percentual,# % for testing\n",
        "    random_state=42,          # for reproducibility\n",
        "    shuffle=True              # shuffle before splitting\n",
        ")\n",
        "\n",
        "val_percentual = 0.1\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    x_train, y_train,          # your train dataset\n",
        "    test_size=val_percentual,  # % of the train data for validation\n",
        "    random_state=42,           # for reproducibility\n",
        "    shuffle=True               # shuffle before splitting\n",
        ")"
      ],
      "metadata": {
        "id": "Wk4bJkbZ7NRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining our Neural Network"
      ],
      "metadata": {
        "id": "-eXdDPZ9Kjah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Modelo CNN simples\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=x_train.shape[1:]),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')  # score between 0 and 1\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "xOskEjfm8sJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=20,\n",
        "                    batch_size=32)\n"
      ],
      "metadata": {
        "id": "y7HEp5KgBujG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Curve"
      ],
      "metadata": {
        "id": "7Bmn80A5NY38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eKrUhtN1Crgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "1YWMwUG8NdWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "y_score = model.predict(x_test).ravel()  # 1D array of probabilities\n",
        "\n",
        "# Convert probabilities to class labels using threshold\n",
        "y_pred_labels = (y_score >= 0.5).astype(int)\n",
        "\n",
        "# Create and display confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix (Sigmoid Output)\")\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6FhxcwqNEEgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC Curve"
      ],
      "metadata": {
        "id": "oRnTt3T-Nh-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Predict probabilities for the validation set\n",
        "y_score = model.predict(x_val).ravel()  # 1D vector with probabilities\n",
        "\n",
        "# Compute False Positive Rate (FPR), True Positive Rate (TPR), and thresholds\n",
        "fpr, tpr, _ = roc_curve(y_val, y_score)\n",
        "\n",
        "# Compute Area Under the Curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # diagonal line for random guessing\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Binary Classification')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zmicyNa4ETVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions\n",
        "1) Are there any issues with your current model? If so, what are they?\n",
        "\n",
        "2) If there are issues, what could you do to address them?\n",
        "\n",
        "# Task\n",
        "Improve the quality of your model based on your observations.\n"
      ],
      "metadata": {
        "id": "8LSuKe8iOJQV"
      }
    }
  ]
}